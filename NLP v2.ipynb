{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3800f704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a78284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Apply Rotary Positional Embedding\n",
    "def apply_rope(q, k):\n",
    "    # q: (B, H, T_q, D), k: (B, H, T_kv, D)\n",
    "    B, H, T_q, D = q.size()\n",
    "    T_kv = k.size(2)\n",
    "    assert D % 2 == 0, \"head_dim phải chẵn để áp dụng RoPE\"\n",
    "\n",
    "    device = q.device\n",
    "    half_dim = D // 2\n",
    "\n",
    "    # Tạo sinusoidal pos embedding cho từng chiều dài\n",
    "    pos_q = torch.arange(T_q, device=device).unsqueeze(1)  # (T_q, 1)\n",
    "    pos_k = torch.arange(T_kv, device=device).unsqueeze(1)  # (T_kv, 1)\n",
    "    dim = torch.arange(half_dim, device=device).unsqueeze(0)  # (1, D/2)\n",
    "    freq = 1.0 / (10000 ** (dim / half_dim))  # (1, D/2)\n",
    "\n",
    "    angle_q = pos_q * freq  # (T_q, D/2)\n",
    "    angle_k = pos_k * freq  # (T_kv, D/2)\n",
    "\n",
    "    sin_q = angle_q.sin()[None, None, :, :]  # (1, 1, T_q, D/2)\n",
    "    cos_q = angle_q.cos()[None, None, :, :]  # (1, 1, T_q, D/2)\n",
    "    sin_k = angle_k.sin()[None, None, :, :]  # (1, 1, T_kv, D/2)\n",
    "    cos_k = angle_k.cos()[None, None, :, :]  # (1, 1, T_kv, D/2)\n",
    "\n",
    "    def rotate(x, sin, cos):\n",
    "        x1 = x[..., ::2]  # even index\n",
    "        x2 = x[..., 1::2]  # odd index\n",
    "        x_rot = torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-1)\n",
    "        return x_rot\n",
    "\n",
    "    return rotate(q, sin_q, cos_q), rotate(k, sin_k, cos_k)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()  # (max_len,1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x_q, x_kv, mask=None):\n",
    "        B, T_q, _ = x_q.size()\n",
    "        T_kv = x_kv.size(1)\n",
    "        q = self.q_proj(x_q).view(B, T_q, self.num_heads, self.head_dim).transpose(1, 2)  # (B, H, T_q, D)\n",
    "        k = self.k_proj(x_kv).view(B, T_kv, self.num_heads, self.head_dim).transpose(1, 2)  # (B, H, T_kv, D)\n",
    "        v = self.v_proj(x_kv).view(B, T_kv, self.num_heads, self.head_dim).transpose(1, 2)  # (B, H, T_kv, D)\n",
    "\n",
    "        # Áp dụng Rotary Positional Embedding tại đây (nếu muốn)\n",
    "        q, k = apply_rope(q, k)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) / self.head_dim**0.5  # scaled dot-product\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        out = attn @ v  # (B, H, T_q, D)\n",
    "        out = out.transpose(1, 2).reshape(B, T_q, -1)\n",
    "        return self.out_proj(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Sửa lại: chỉ truyền x, x, mask\n",
    "        attn = self.self_attn(x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn))\n",
    "        ff = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff))\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_attn  = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff        = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n",
    "        # Sửa lại: chỉ truyền x, x, tgt_mask\n",
    "        attn1 = self.self_attn(x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn1))\n",
    "        # Sửa lại: truyền x, enc_out, src_mask\n",
    "        attn2 = self.enc_attn(x, enc_out, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn2))\n",
    "        ff = self.ff(x)\n",
    "        x = self.norm3(x + self.dropout(ff))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, num_heads=8, d_ff=2048,\n",
    "                 num_encoder=6, num_decoder=6, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = nn.Embedding(src_vocab, d_model)\n",
    "        self.tgt_tok_emb = nn.Embedding(tgt_vocab, d_model)\n",
    "        self.enc_layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_encoder)]\n",
    "        )\n",
    "        self.dec_layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_decoder)]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        return (src != 0).unsqueeze(1).unsqueeze(2)  # (B,1,1,src_len)\n",
    "\n",
    "    def make_tgt_mask(self, tgt):\n",
    "        B, tgt_len = tgt.size()\n",
    "        pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)  # (B,1,1,tgt_len)\n",
    "        subseq_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
    "        return pad_mask & subseq_mask  # (B,1,tgt_len,tgt_len)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        tgt_mask = self.make_tgt_mask(tgt)\n",
    "        # Embedding + Positional\n",
    "        enc = self.src_tok_emb(src)\n",
    "        for layer in self.enc_layers:\n",
    "            enc = layer(enc, src_mask)\n",
    "        dec = self.tgt_tok_emb(tgt)\n",
    "        for layer in self.dec_layers:\n",
    "            dec = layer(dec, enc, src_mask, tgt_mask)\n",
    "        out = self.fc_out(dec)  # (B, tgt_len, tgt_vocab)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f9c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VLDataset(Dataset):\n",
    "    def __init__(self, src_lines, tgt_lines, spm_model, max_len=128):\n",
    "        import sentencepiece as spm\n",
    "        self.sp = spm.SentencePieceProcessor(model_file=spm_model)\n",
    "        self.src, self.tgt = src_lines, tgt_lines\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): return len(self.src)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        src_ids = self.sp.encode(self.src[i])[:self.max_len]\n",
    "        tgt_ids = self.sp.encode(self.tgt[i])[:self.max_len]\n",
    "        return {\n",
    "            \"src\": torch.tensor([1] + src_ids + [2]),   # <s>=1, </s>=2\n",
    "            \"tgt\": torch.tensor([1] + tgt_ids + [2])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e02dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cẩn thận\n",
    "import sentencepiece as spm\n",
    "# Chuẩn bị file đầu vào chứa cả Lào và Việt (hoặc 2 file riêng)\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='data/Train/train2023.vi,data/Train/train2023.lo',\n",
    "    model_prefix='vietlao_spm', vocab_size=32000, character_coverage=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48530269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs = [b[\"src\"] for b in batch]\n",
    "    tgts = [b[\"tgt\"] for b in batch]\n",
    "    src_pad = nn.utils.rnn.pad_sequence(srcs, padding_value=0, batch_first=True)\n",
    "    tgt_pad = nn.utils.rnn.pad_sequence(tgts, padding_value=0, batch_first=True)\n",
    "    return src_pad, tgt_pad\n",
    "\n",
    "# Example data, replace with your actual data loading\n",
    "with open('./data/Train/train2023.vi', encoding='utf-8') as f:\n",
    "    train_vi = [line.strip() for line in f if line.strip()]\n",
    "with open('./data/Train/train2023.lo', encoding='utf-8') as f:\n",
    "    train_lo = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "train_ds = VLDataset(train_vi, train_lo, \"./vietlao_spm.model\")\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,\n",
    "                          num_workers=0, pin_memory=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8fd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kích thước từ điển\n",
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file='./vietlao_spm.model')\n",
    "vocab_size = sp.get_piece_size()\n",
    "src_vocab = vocab_size\n",
    "tgt_vocab = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc743f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 32000\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file='./vietlao_spm.model')\n",
    "vocab_size = sp.get_piece_size()\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f373cffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1272\\4064866921.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # Khởi tạo scaler (chỉ cần 1 lần, ngoài vòng lặp)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1272\\4064866921.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     loss = criterion(output.reshape(-\u001b[32m1\u001b[39m, output.size(-\u001b[32m1\u001b[39m)), tgt_out.reshape(-\u001b[32m1\u001b[39m))\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# backward + step qua GradScaler\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m scaler.step(optimizer)\n\u001b[32m     26\u001b[39m scaler.update()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Viet-Lao\\env\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Viet-Lao\\env\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Viet-Lao\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = Transformer(src_vocab, tgt_vocab).cuda()\n",
    "model = nn.DataParallel(model)  # sẽ tự chia batch trên tất cả GPU; với 1 GPU cũng hoạt động bình thường\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9,0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()  # Khởi tạo scaler (chỉ cần 1 lần, ngoài vòng lặp)\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.cuda(), tgt.cuda()\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_out = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Bật autocast để dùng mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(src, tgt_in)  # forward\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "        # backward + step qua GradScaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu checkpoint\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state': model.state_dict(),\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'scaler_state': scaler.state_dict(),\n",
    "}, \"checkpoints/checkpoint_epoch10.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu model\n",
    "torch.save(model.state_dict(), f\"checkpoints/transformer_epoch{epoch}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f07dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Transformer(\n",
       "    (src_tok_emb): Embedding(32000, 512)\n",
       "    (tgt_tok_emb): Embedding(32000, 512)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (enc_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dec_layers): ModuleList(\n",
       "      (0-5): 6 x DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=512, out_features=32000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model đã train\n",
    "model = Transformer(src_vocab, tgt_vocab)  # Khởi tạo lại kiến trúc như lúc train\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(\"checkpoints/transformer_epoch10.pt\"))\n",
    "model.eval()\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce6feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"vietlao_spm.model\")\n",
    "\n",
    "BOS_ID = sp.bos_id()\n",
    "EOS_ID = sp.eos_id()\n",
    "PAD_ID = sp.pad_id()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9853ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_vi_to_lo(sentence, model, sp, max_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 1. Tokenize tiếng Việt\n",
    "        src_ids = [BOS_ID] + sp.encode(sentence) + [EOS_ID]\n",
    "        src_tensor = torch.LongTensor(src_ids).unsqueeze(0).cuda()  # (1, src_len)\n",
    "\n",
    "        # 2. Tạo target đầu vào với chỉ BOS\n",
    "        tgt_ids = [BOS_ID]\n",
    "        for _ in range(max_len):\n",
    "            tgt_tensor = torch.LongTensor(tgt_ids).unsqueeze(0).cuda()  # (1, tgt_len)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(src_tensor, tgt_tensor)\n",
    "            next_token = output[0, -1].argmax(-1).item()\n",
    "            if next_token == EOS_ID:\n",
    "                break\n",
    "            tgt_ids.append(next_token)\n",
    "\n",
    "        # 3. Decode tiếng Lào\n",
    "        return sp.decode(tgt_ids[1:])  # bỏ BOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025427da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dịch: ແມວເມື່ອແຊບ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10048\\4076700175.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "sentence = \"con mèo khi trông ngon quá\"\n",
    "translated = translate_vi_to_lo(sentence, model, sp)\n",
    "print(\"Dịch:\", translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76f3d8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7636\\4076700175.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 16.80\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# Load dữ liệu test\n",
    "with open(\"data/Dev/dev2023.vi\", encoding=\"utf-8\") as f:\n",
    "    src_sentences = [line.strip() for line in f if line.strip()]\n",
    "with open(\"data/Dev/dev2023.lo\", encoding=\"utf-8\") as f:\n",
    "    ref_sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Dịch toàn bộ\n",
    "hyp_sentences = [translate_vi_to_lo(sent, model, sp) for sent in src_sentences]\n",
    "\n",
    "# Tính BLEU\n",
    "bleu = sacrebleu.corpus_bleu(hyp_sentences, [ref_sentences])\n",
    "print(f\"BLEU: {bleu.score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
