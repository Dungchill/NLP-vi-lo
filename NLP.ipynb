{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3800f704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a78284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()  # (max_len,1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        # projection layers\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        B, Ql, _ = query.size()\n",
    "        Kl, Vl = key.size(1), value.size(1)\n",
    "        # linear projections\n",
    "        Q = self.w_q(query)  # (B, Ql, d_model)\n",
    "        K = self.w_k(key)\n",
    "        V = self.w_v(value)\n",
    "        # split into heads\n",
    "        Q = Q.view(B, Ql, self.num_heads, self.head_dim).transpose(1,2)  # (B, heads, Ql, head_dim)\n",
    "        K = K.view(B, Kl, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        V = V.view(B, Vl, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        # scaled dot-product\n",
    "        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.head_dim)  # (B, heads, Ql, Kl)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e4)\n",
    "        attn = torch.softmax(scores, dim=-1)  # (B, heads, Ql, Kl)\n",
    "        out = attn @ V  # (B, heads, Ql, head_dim)\n",
    "        out = out.transpose(1,2).contiguous().view(B, Ql, -1)  # (B, Ql, d_model)\n",
    "        return self.fc_out(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Self-attention\n",
    "        attn = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn))\n",
    "        # Feed-forward\n",
    "        ff = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff))\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_attn  = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff        = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n",
    "        # Masked self-attention\n",
    "        attn1 = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn1))\n",
    "        # Encoder-decoder attention\n",
    "        attn2 = self.enc_attn(x, enc_out, enc_out, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn2))\n",
    "        # Feed-forward\n",
    "        ff = self.ff(x)\n",
    "        x = self.norm3(x + self.dropout(ff))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, num_heads=8, d_ff=2048,\n",
    "                 num_encoder=6, num_decoder=6, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = nn.Embedding(src_vocab, d_model)\n",
    "        self.tgt_tok_emb = nn.Embedding(tgt_vocab, d_model)\n",
    "        self.pos_enc     = PositionalEncoding(d_model, max_len)\n",
    "        self.enc_layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_encoder)]\n",
    "        )\n",
    "        self.dec_layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_decoder)]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        return (src != 0).unsqueeze(1).unsqueeze(2)  # (B,1,1,src_len)\n",
    "\n",
    "    def make_tgt_mask(self, tgt):\n",
    "        B, tgt_len = tgt.size()\n",
    "        pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)  # (B,1,1,tgt_len)\n",
    "        subseq_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
    "        return pad_mask & subseq_mask  # (B,1,tgt_len,tgt_len)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        tgt_mask = self.make_tgt_mask(tgt)\n",
    "        # Embedding + Positional\n",
    "        enc = self.pos_enc(self.src_tok_emb(src))\n",
    "        for layer in self.enc_layers:\n",
    "            enc = layer(enc, src_mask)\n",
    "        dec = self.pos_enc(self.tgt_tok_emb(tgt))\n",
    "        for layer in self.dec_layers:\n",
    "            dec = layer(dec, enc, src_mask, tgt_mask)\n",
    "        out = self.fc_out(dec)  # (B, tgt_len, tgt_vocab)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f9c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VLDataset(Dataset):\n",
    "    def __init__(self, src_lines, tgt_lines, spm_model, max_len=128):\n",
    "        import sentencepiece as spm\n",
    "        self.sp = spm.SentencePieceProcessor(model_file=spm_model)\n",
    "        self.src, self.tgt = src_lines, tgt_lines\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): return len(self.src)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        src_ids = self.sp.encode(self.src[i])[:self.max_len]\n",
    "        tgt_ids = self.sp.encode(self.tgt[i])[:self.max_len]\n",
    "        return {\n",
    "            \"src\": torch.tensor([1] + src_ids + [2]),   # <s>=1, </s>=2\n",
    "            \"tgt\": torch.tensor([1] + tgt_ids + [2])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e02dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cẩn thận\n",
    "import sentencepiece as spm\n",
    "# Chuẩn bị file đầu vào chứa cả Lào và Việt (hoặc 2 file riêng)\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='data/Train/train2023.vi,data/Train/train2023.lo',\n",
    "    model_prefix='vietlao_spm', vocab_size=32000, character_coverage=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48530269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs = [b[\"src\"] for b in batch]\n",
    "    tgts = [b[\"tgt\"] for b in batch]\n",
    "    src_pad = nn.utils.rnn.pad_sequence(srcs, padding_value=0, batch_first=True)\n",
    "    tgt_pad = nn.utils.rnn.pad_sequence(tgts, padding_value=0, batch_first=True)\n",
    "    return src_pad, tgt_pad\n",
    "\n",
    "# Example data, replace with your actual data loading\n",
    "with open('./data/Train/train2023.vi', encoding='utf-8') as f:\n",
    "    train_vi = [line.strip() for line in f if line.strip()]\n",
    "with open('./data/Train/train2023.lo', encoding='utf-8') as f:\n",
    "    train_lo = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "train_ds = VLDataset(train_vi, train_lo, \"./vietlao_spm.model\")\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,\n",
    "                          num_workers=0, pin_memory=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8fd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kích thước từ điển\n",
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file='./vietlao_spm.model')\n",
    "vocab_size = sp.get_piece_size()\n",
    "src_vocab = vocab_size\n",
    "tgt_vocab = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc743f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 32000\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file='./vietlao_spm.model')\n",
    "vocab_size = sp.get_piece_size()\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f373cffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7636\\4064866921.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # Khởi tạo scaler (chỉ cần 1 lần, ngoài vòng lặp)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7636\\4064866921.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.4934\n",
      "Epoch 2, Loss: 5.2823\n",
      "Epoch 3, Loss: 4.6515\n",
      "Epoch 4, Loss: 4.1647\n",
      "Epoch 5, Loss: 3.7555\n",
      "Epoch 6, Loss: 3.3908\n",
      "Epoch 7, Loss: 3.0619\n",
      "Epoch 8, Loss: 2.7610\n",
      "Epoch 9, Loss: 2.4912\n",
      "Epoch 10, Loss: 2.2469\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(src_vocab, tgt_vocab).cuda()\n",
    "model = nn.DataParallel(model)  # sẽ tự chia batch trên tất cả GPU; với 1 GPU cũng hoạt động bình thường\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9,0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()  # Khởi tạo scaler (chỉ cần 1 lần, ngoài vòng lặp)\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.cuda(), tgt.cuda()\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_out = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Bật autocast để dùng mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(src, tgt_in)  # forward\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "        # backward + step qua GradScaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu checkpoint\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state': model.state_dict(),\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'scaler_state': scaler.state_dict(),\n",
    "}, \"checkpoints/checkpoint_epoch10.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu model\n",
    "torch.save(model.state_dict(), f\"checkpoints/transformer_epoch{epoch}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f07dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Transformer(\n",
       "    (src_tok_emb): Embedding(32000, 512)\n",
       "    (tgt_tok_emb): Embedding(32000, 512)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (enc_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dec_layers): ModuleList(\n",
       "      (0-5): 6 x DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=512, out_features=32000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model đã train\n",
    "model = Transformer(src_vocab, tgt_vocab)  # Khởi tạo lại kiến trúc như lúc train\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(\"checkpoints/transformer_epoch10.pt\"))\n",
    "model.eval()\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce6feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"vietlao_spm.model\")\n",
    "\n",
    "BOS_ID = sp.bos_id()\n",
    "EOS_ID = sp.eos_id()\n",
    "PAD_ID = sp.pad_id()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9853ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_vi_to_lo(sentence, model, sp, max_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 1. Tokenize tiếng Việt\n",
    "        src_ids = [BOS_ID] + sp.encode(sentence) + [EOS_ID]\n",
    "        src_tensor = torch.LongTensor(src_ids).unsqueeze(0).cuda()  # (1, src_len)\n",
    "\n",
    "        # 2. Tạo target đầu vào với chỉ BOS\n",
    "        tgt_ids = [BOS_ID]\n",
    "        for _ in range(max_len):\n",
    "            tgt_tensor = torch.LongTensor(tgt_ids).unsqueeze(0).cuda()  # (1, tgt_len)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(src_tensor, tgt_tensor)\n",
    "            next_token = output[0, -1].argmax(-1).item()\n",
    "            if next_token == EOS_ID:\n",
    "                break\n",
    "            tgt_ids.append(next_token)\n",
    "\n",
    "        # 3. Decode tiếng Lào\n",
    "        return sp.decode(tgt_ids[1:])  # bỏ BOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025427da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dịch: ແມວເມື່ອແຊບ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10048\\4076700175.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "sentence = \"con mèo khi trông ngon quá\"\n",
    "translated = translate_vi_to_lo(sentence, model, sp)\n",
    "print(\"Dịch:\", translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76f3d8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7636\\4076700175.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 16.80\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# Load dữ liệu test\n",
    "with open(\"data/Dev/dev2023.vi\", encoding=\"utf-8\") as f:\n",
    "    src_sentences = [line.strip() for line in f if line.strip()]\n",
    "with open(\"data/Dev/dev2023.lo\", encoding=\"utf-8\") as f:\n",
    "    ref_sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Dịch toàn bộ\n",
    "hyp_sentences = [translate_vi_to_lo(sent, model, sp) for sent in src_sentences]\n",
    "\n",
    "# Tính BLEU\n",
    "bleu = sacrebleu.corpus_bleu(hyp_sentences, [ref_sentences])\n",
    "print(f\"BLEU: {bleu.score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
